<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Concepts/Introduction" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">Introduction to Generative AI and Large Language Models | Prompt Engineering for generative AI (PE4GenAI)</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://antbucc.github.io/PE4GenAI/Concepts/Introduction/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Introduction to Generative AI and Large Language Models | Prompt Engineering for generative AI (PE4GenAI)"><meta data-rh="true" name="description" content="A statistical approach to AI: Machine Learning"><meta data-rh="true" property="og:description" content="A statistical approach to AI: Machine Learning"><link data-rh="true" rel="icon" href="/PE4GenAI/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://antbucc.github.io/PE4GenAI/Concepts/Introduction/"><link data-rh="true" rel="alternate" href="https://antbucc.github.io/PE4GenAI/Concepts/Introduction/" hreflang="en"><link data-rh="true" rel="alternate" href="https://antbucc.github.io/PE4GenAI/Concepts/Introduction/" hreflang="x-default"><link rel="stylesheet" href="/PE4GenAI/assets/css/styles.7e19db31.css">
<script src="/PE4GenAI/assets/js/runtime~main.eeb0e763.js" defer="defer"></script>
<script src="/PE4GenAI/assets/js/main.70ac9b80.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/PE4GenAI/"><div class="navbar__logo"><img src="/PE4GenAI/img/logo-ws3.png" alt="Prompt Engineering for generative AI" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/PE4GenAI/img/logo-ws3.png" alt="Prompt Engineering for generative AI" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Prompt Engineering for generative AI</b></a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/PE4GenAI/">Welcome</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/PE4GenAI/survey/">Let&#x27;s Start</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/PE4GenAI/installation/">PlayGround</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/PE4GenAI/Metrics/Relevance/">Metrics</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/PE4GenAI/Card Creation/newCard/">Card Creation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/PE4GenAI/Concepts/Introduction/">Concepts</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/PE4GenAI/Concepts/Introduction/">Introduction to Generative AI and Large Language Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/PE4GenAI/ai-models/">AI Models &amp; Deployments</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/PE4GenAI/llms/">Large Language Model (LLM)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/PE4GenAI/tokenization/">Tokenization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/PE4GenAI/Concepts/Techniques/">Prompt engineering techniques</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/PE4GenAI/setup/">Get started</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/PE4GenAI/summary/">Summary</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/PE4GenAI/Theory/intro/">Theory</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/PE4GenAI/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Concepts</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Introduction to Generative AI and Large Language Models</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Introduction to Generative AI and Large Language Models</h1>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-statistical-approach-to-ai-machine-learning">A statistical approach to AI: Machine Learning<a href="#a-statistical-approach-to-ai-machine-learning" class="hash-link" aria-label="Direct link to A statistical approach to AI: Machine Learning" title="Direct link to A statistical approach to AI: Machine Learning">​</a></h3>
<p>A turning point arrived during the 90s, with the application of a <strong>statistical approach to text analysis</strong>. This led to the development of new algorithms – known with the name of <strong>machine learnin</strong>g** - able to learn <strong>patterns from data</strong>, without being explicitly programmed. This approach allows a machine to simulate <strong>human language understanding</strong>: a statistical model is trained on text-label pairings, enabling the model to classify unknown input text with a pre-defined label representing the intention of the message.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="neural-networks-and-modern-virtual-assistants">Neural networks and modern virtual assistants<a href="#neural-networks-and-modern-virtual-assistants" class="hash-link" aria-label="Direct link to Neural networks and modern virtual assistants" title="Direct link to Neural networks and modern virtual assistants">​</a></h3>
<p>In more recent times, the technological evolution of the hardware, capable of handling larger amounts of data and more complex computations, encouraged research in the AI fields, leading to the development of advanced machine learning algorithms – called <strong>neural networks</strong> or <strong>deep learning</strong> algorithms.</p>
<p><strong>Neural networks</strong> (and in particular Recurrent Neural Networks – RNNs) significantly enhanced <strong>natural language processing</strong>, enabling the representation of the <em><strong>meaning of text</strong></em> in a more meaningful way, valuing the context of a word in a sentence.</p>
<p>This is the technology that powered the <strong>virtual assistants</strong> born in the first decade of the new century, very proficient in interpreting the human language, identifying a need, and performing an action to satisfy it – like answering with a pre-defined script or consuming a 3rd party service.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="present-day-generative-ai">Present day, Generative AI<a href="#present-day-generative-ai" class="hash-link" aria-label="Direct link to Present day, Generative AI" title="Direct link to Present day, Generative AI">​</a></h3>
<p>So that’s how we came to Generative AI today, which can be seen as a subset of deep learning.</p>
<p><img decoding="async" loading="lazy" alt="AI, ML, DL and Generative AI" src="/PE4GenAI/assets/images/AI-diagram-d15b6216e5fb3739d67dfa87c94afc92.png" width="975" height="530" class="img_ev3q"></p>
<p>After decades of research in the AI field, a new model architecture – called <em>Transformer</em> – overcame the limits of RNNs, being able to get much longer sequences of text as input. Transformers are based on the attention mechanism, enabling the model to give <strong>different weights to the inputs it receives</strong>, ‘paying more attention’ where the most relevant information is concentrated, regardless of their order in the text sequence.</p>
<p>Most of the recent generative AI models – also known as <strong>Large Language Models (LLMs)</strong>, since they work with textual inputs and outputs – are indeed based on this architecture. What’s interesting about these models – trained on a huge amount of unlabeled data from diverse sources like books, articles and websites – is that they can be adapted to a wide variety of tasks and generate grammatically correct text with a semblance of creativity. So, not only did they incredibly enhance the capacity of a machine to ‘understand’ an input text, but they enabled their capacity to generate an original response in human language.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-do-large-language-models-work">How do large language models work?<a href="#how-do-large-language-models-work" class="hash-link" aria-label="Direct link to How do large language models work?" title="Direct link to How do large language models work?">​</a></h2>
<p>Let’s have a look at how large language models work, with a focus on OpenAI GPT (Generative Pre-trained Transformer) models.</p>
<ul>
<li><strong>Tokenizer, text to numbers</strong>: Large Language Models receive a text as input and generate a text as output. However, being statistical models, they work much better with <strong>numbers</strong> than text sequences. That’s why every input to the model is processed by a <em><strong>tokenizer</strong></em>, before being used by the core model. A token is a chunk of text – consisting of a variable number of characters, so the tokenizer&#x27;s main task is splitting the input into an array of tokens. Then, each token is mapped with a token index, which is the integer encoding of the original text chunk.</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Example of tokenization" src="/PE4GenAI/assets/images/tokenizer-example-66485c67d9c21fc0742a68a70e1164ed.png" width="824" height="249" class="img_ev3q"></p>
<ul>
<li>
<p><strong>Predicting output tokens</strong>: Given n tokens as input (with max n varying from one model to another), the model is able to predict one token as output. This token is then incorporated into the input of the next iteration, in an expanding window pattern, enabling a better user experience of getting one (or multiple) sentence as an answer. This explains why, if you ever played with ChatGPT, you might have noticed that sometimes it looks like it stops in the middle of a sentence.</p>
</li>
<li>
<p><strong>Selection process, probability distribution</strong>: The output token is chosen by the model according to its probability of occurring after the current text sequence. This is because the model predicts a probability distribution over all possible ‘next tokens’, calculated based on its training. However, not always the token with the highest probability is chosen from the resulting distribution. A <strong>degree of randomness</strong> is added to this choice, in a way that the model acts in a non-deterministic fashion - we do not get the exact same output for the same input. This degree of randomness is added to simulate the process of creative thinking and it can be tuned using a model parameter called temperature.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="practical-examples">Practical Examples<a href="#practical-examples" class="hash-link" aria-label="Direct link to Practical Examples" title="Direct link to Practical Examples">​</a></h2>
<p>Now that we have a better understanding of the inner working of a large language model, let’s see some practical examples of the most <strong>common tasks</strong> they can perform pretty well, with an eye to our business scenario.
We said that the main capability of a Large Language Model is <em>generating a text from scratch, starting from a textual input, written in natural language</em>.</p>
<p>But what kind of textual input and output?
The input of a large language model is known as <strong>prompt</strong>, while the output is known as <strong>completion</strong>, term that refers to the model mechanism of generating the next token to complete the current input. We are going to dive deep into what is a prompt and how to design it in a way to get the most out of our model. But for now, let’s just say that a prompt may include:</p>
<ul>
<li>
<p>An <strong>instruction</strong> specifying the type of output we expect from the model. This instruction sometimes might embed some examples or some additional data.</p>
<ol>
<li>Summarization of an article, book, product reviews and more, along with extraction of insights from unstructured data.</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Example of summarization" src="/PE4GenAI/assets/images/summarization-example-f176da1133532368558d2de2831978e9.png" width="678" height="720" class="img_ev3q"></p>
<ol start="2">
<li>Creative ideation and design of an article, an essay, an assignment or more.</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Example of creative writing" src="/PE4GenAI/assets/images/creative-writing-example-e381b6a59ea6c9b3559b97c65c0aed39.png" width="619" height="720" class="img_ev3q"></p>
</li>
<li>
<p>A <strong>question</strong>, asked in the form of a conversation with an agent.</p>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Example of conversation" src="/PE4GenAI/assets/images/conversation-example-11cd2614006f9c0fdf3c5297a3320c08.png" width="701" height="720" class="img_ev3q"></p>
<ul>
<li>A chunk of <strong>text to complete</strong>, which implicitly is an ask for writing assistance.</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Example of text completion" src="/PE4GenAI/assets/images/text-completion-example-660f4ae21ea319fbb8a67daa69199c65.png" width="632" height="720" class="img_ev3q"></p>
<ul>
<li>A chunk of <strong>code</strong> together with the ask of explaining and documenting it, or a comment asking to generate a piece of code performing a specific task.</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Coding example" src="/PE4GenAI/assets/images/coding-example-233637c73da57594e7a7fb97ec5c1e0b.png" width="714" height="720" class="img_ev3q"></p>
<p>The examples above are quite simple and don’t want to be an exhaustive demonstration of Large Language Models capabilities. They just want to show the potential of using generative AI, in particular but not limited to educational context.</p>
<p>Also, the output of a generative AI model is not perfect and sometimes the creativity of the model can work against it, resulting in an output which is a combination of words that the human user can interpret as a mystification of reality, or it can be offensive. Generative AI is not intelligent - at least in the more comprehensive definition of intelligence, including critical and creative reasoning or emotional intelligence; it is not deterministic, and it is not trustworthy, since fabrications, such as erroneous references, content, and statements, may be combined with correct information, and presented in a persuasive and confident manner. In the following lessons, we’ll be dealing with all these limitations and we’ll see what we can do to mitigate them.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/PE4GenAI/Card Creation/Context/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Add knowledge</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/PE4GenAI/ai-models/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">AI Models &amp; Deployments</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#a-statistical-approach-to-ai-machine-learning" class="table-of-contents__link toc-highlight">A statistical approach to AI: Machine Learning</a></li><li><a href="#neural-networks-and-modern-virtual-assistants" class="table-of-contents__link toc-highlight">Neural networks and modern virtual assistants</a></li><li><a href="#present-day-generative-ai" class="table-of-contents__link toc-highlight">Present day, Generative AI</a></li><li><a href="#how-do-large-language-models-work" class="table-of-contents__link toc-highlight">How do large language models work?</a></li><li><a href="#practical-examples" class="table-of-contents__link toc-highlight">Practical Examples</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Prompt Engineering for Generative AI (PE4GenAI).</div></div></div></footer></div>
</body>
</html>